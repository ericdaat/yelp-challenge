{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Yelp Reviews Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gensim.models as m\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Building a Corpus Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in open(self.path):\n",
    "            yield line\n",
    "\n",
    "\n",
    "class JsonCorpus(Corpus):\n",
    "    def __init__(self, path):\n",
    "        super(JsonCorpus, self).__init__(path)\n",
    "            \n",
    "            \n",
    "    def __parse_json(self, line):\n",
    "        return json.loads(line)\n",
    "            \n",
    "        \n",
    "    def head(self, n, return_type='json', pos_threshold=3):\n",
    "        with open(self.path) as file:\n",
    "            json = [self.__parse_json(next(file).strip()) for x in xrange(n)]\n",
    "            \n",
    "            if return_type is 'json':\n",
    "                return json\n",
    "            elif return_type is 'text_rating':\n",
    "                return [[j['text'], j['stars']] for j in json]\n",
    "            elif return_type is 'text_sentiment':\n",
    "                return [[j['text'], 'pos' if j['stars'] > pos_threshold else 'neg'] for j in json]\n",
    "            else:\n",
    "                raise NameError('invalid return_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "corpus = JsonCorpus('../dataset/yelp_academic_dataset_review.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'Mr Hoagie is an institution. Walking in, it does seem like a throwback to 30 years ago, old fashioned menu board, booths out of the 70s, and a large selection of food. Their speciality is the Italian Hoagie, and it is voted the best in the area year after year. I usually order the burger, while the patties are obviously cooked from frozen, all of the other ingredients are very fresh. Overall, its a good alternative to Subway, which is down the road.',\n",
       "  'pos']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head(1, 'text_sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## NLP with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Playground Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocabulary = [c[0] for c in corpus.head(100, 'text_sentiment')]\n",
    "sentiment = [c[1] for c in corpus.head(100, 'text_sentiment')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2176)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "multinomial_naive_bayes = MultinomialNB()\n",
    "clf = multinomial_naive_bayes.fit(X_train_counts, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos']\n",
      "['neg']\n"
     ]
    }
   ],
   "source": [
    "print clf.predict(count_vectorizer.transform(['this is good food']))\n",
    "print clf.predict(count_vectorizer.transform(['that place was bad']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Improving classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = [c[0] for c in corpus.head(20000, 'text_sentiment')], [c[1] for c in corpus.head(20000, 'text_sentiment')]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_clf_1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "text_clf_2 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', SGDClassifier(loss='hinge', \n",
    "                          penalty='l2', \n",
    "                          alpha=1e-3, \n",
    "                          n_iter=5, \n",
    "                          random_state=42)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.93 s, sys: 57.3 ms, total: 1.98 s\n",
      "Wall time: 1.97 s\n",
      "\n",
      "text_clf_1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.79      0.71      0.75      2374\n",
      "        pos       0.85      0.89      0.87      4226\n",
      "\n",
      "avg / total       0.82      0.83      0.82      6600\n",
      " \n",
      "\n",
      "CPU times: user 2.09 s, sys: 217 ms, total: 2.31 s\n",
      "Wall time: 2.2 s\n",
      "\n",
      "text_clf_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.90      0.58      0.70      2374\n",
      "        pos       0.80      0.96      0.88      4226\n",
      "\n",
      "avg / total       0.84      0.83      0.81      6600\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time text_clf_1.fit(X_train, y_train)\n",
    "print '\\ntext_clf_1\\n %s \\n' %metrics.classification_report(y_test, \n",
    "                                                            text_clf_1.predict(X_test))\n",
    "\n",
    "%time text_clf_2.fit(X_train, y_train)\n",
    "print '\\ntext_clf_2\\n %s \\n' %metrics.classification_report(y_test, \n",
    "                                                            text_clf_2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos']\n",
      "['neg']\n"
     ]
    }
   ],
   "source": [
    "print text_clf_2.predict(['oh I love this place it is so good the food is nice'])\n",
    "print text_clf_2.predict(['the food was really super bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf_2, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...     penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
       "       warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (0.01, 0.001)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.514964</td>\n",
       "      <td>1.176068</td>\n",
       "      <td>0.815149</td>\n",
       "      <td>0.840485</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{u'vect__ngram_range': (1, 1), u'tfidf__use_id...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807520</td>\n",
       "      <td>0.841245</td>\n",
       "      <td>0.814375</td>\n",
       "      <td>0.842064</td>\n",
       "      <td>0.823556</td>\n",
       "      <td>0.838146</td>\n",
       "      <td>0.061501</td>\n",
       "      <td>0.010844</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.001687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.677888</td>\n",
       "      <td>1.220552</td>\n",
       "      <td>0.793806</td>\n",
       "      <td>0.807724</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{u'vect__ngram_range': (1, 1), u'tfidf__use_id...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.790734</td>\n",
       "      <td>0.806538</td>\n",
       "      <td>0.788401</td>\n",
       "      <td>0.809828</td>\n",
       "      <td>0.802284</td>\n",
       "      <td>0.806805</td>\n",
       "      <td>0.122359</td>\n",
       "      <td>0.060093</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>0.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.585097</td>\n",
       "      <td>2.645326</td>\n",
       "      <td>0.790896</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{u'vect__ngram_range': (1, 2), u'tfidf__use_id...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.789167</td>\n",
       "      <td>0.810233</td>\n",
       "      <td>0.784147</td>\n",
       "      <td>0.808708</td>\n",
       "      <td>0.799373</td>\n",
       "      <td>0.813186</td>\n",
       "      <td>0.373139</td>\n",
       "      <td>0.024620</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.001859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.255774</td>\n",
       "      <td>3.961326</td>\n",
       "      <td>0.722239</td>\n",
       "      <td>0.725859</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{u'vect__ngram_range': (1, 2), u'tfidf__use_id...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.727171</td>\n",
       "      <td>0.731079</td>\n",
       "      <td>0.721451</td>\n",
       "      <td>0.723416</td>\n",
       "      <td>0.718092</td>\n",
       "      <td>0.723080</td>\n",
       "      <td>0.208553</td>\n",
       "      <td>0.050215</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.003694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.716545</td>\n",
       "      <td>1.379582</td>\n",
       "      <td>0.628731</td>\n",
       "      <td>0.628657</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{u'vect__ngram_range': (1, 1), u'tfidf__use_id...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.628469</td>\n",
       "      <td>0.628751</td>\n",
       "      <td>0.629198</td>\n",
       "      <td>0.628498</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>0.628722</td>\n",
       "      <td>0.036988</td>\n",
       "      <td>0.060439</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.585405</td>\n",
       "      <td>1.151708</td>\n",
       "      <td>0.628507</td>\n",
       "      <td>0.628507</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{u'vect__ngram_range': (1, 1), u'tfidf__use_id...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.628469</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>0.628498</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>0.628498</td>\n",
       "      <td>0.044785</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.339675</td>\n",
       "      <td>3.655587</td>\n",
       "      <td>0.628507</td>\n",
       "      <td>0.628507</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{u'vect__ngram_range': (1, 2), u'tfidf__use_id...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.628469</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>0.628498</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>0.628498</td>\n",
       "      <td>0.331686</td>\n",
       "      <td>0.031999</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.036358</td>\n",
       "      <td>3.260350</td>\n",
       "      <td>0.628507</td>\n",
       "      <td>0.628507</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{u'vect__ngram_range': (1, 2), u'tfidf__use_id...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.628469</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>0.628498</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>0.628498</td>\n",
       "      <td>0.298908</td>\n",
       "      <td>0.074574</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "4       2.514964         1.176068         0.815149          0.840485   \n",
       "6       2.677888         1.220552         0.793806          0.807724   \n",
       "7       8.585097         2.645326         0.790896          0.810709   \n",
       "5      11.255774         3.961326         0.722239          0.725859   \n",
       "2       2.716545         1.379582         0.628731          0.628657   \n",
       "0       2.585405         1.151708         0.628507          0.628507   \n",
       "1      11.339675         3.655587         0.628507          0.628507   \n",
       "3      10.036358         3.260350         0.628507          0.628507   \n",
       "\n",
       "  param_clf__alpha param_tfidf__use_idf param_vect__ngram_range  \\\n",
       "4            0.001                 True                  (1, 1)   \n",
       "6            0.001                False                  (1, 1)   \n",
       "7            0.001                False                  (1, 2)   \n",
       "5            0.001                 True                  (1, 2)   \n",
       "2             0.01                False                  (1, 1)   \n",
       "0             0.01                 True                  (1, 1)   \n",
       "1             0.01                 True                  (1, 2)   \n",
       "3             0.01                False                  (1, 2)   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "4  {u'vect__ngram_range': (1, 1), u'tfidf__use_id...                1   \n",
       "6  {u'vect__ngram_range': (1, 1), u'tfidf__use_id...                2   \n",
       "7  {u'vect__ngram_range': (1, 2), u'tfidf__use_id...                3   \n",
       "5  {u'vect__ngram_range': (1, 2), u'tfidf__use_id...                4   \n",
       "2  {u'vect__ngram_range': (1, 1), u'tfidf__use_id...                5   \n",
       "0  {u'vect__ngram_range': (1, 1), u'tfidf__use_id...                6   \n",
       "1  {u'vect__ngram_range': (1, 2), u'tfidf__use_id...                6   \n",
       "3  {u'vect__ngram_range': (1, 2), u'tfidf__use_id...                6   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "4           0.807520            0.841245           0.814375   \n",
       "6           0.790734            0.806538           0.788401   \n",
       "7           0.789167            0.810233           0.784147   \n",
       "5           0.727171            0.731079           0.721451   \n",
       "2           0.628469            0.628751           0.629198   \n",
       "0           0.628469            0.628527           0.628527   \n",
       "1           0.628469            0.628527           0.628527   \n",
       "3           0.628469            0.628527           0.628527   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "4            0.842064           0.823556            0.838146      0.061501   \n",
       "6            0.809828           0.802284            0.806805      0.122359   \n",
       "7            0.808708           0.799373            0.813186      0.373139   \n",
       "5            0.723416           0.718092            0.723080      0.208553   \n",
       "2            0.628498           0.628527            0.628722      0.036988   \n",
       "0            0.628498           0.628527            0.628498      0.044785   \n",
       "1            0.628498           0.628527            0.628498      0.331686   \n",
       "3            0.628498           0.628527            0.628498      0.298908   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "4        0.010844        0.006570         0.001687  \n",
       "6        0.060093        0.006069         0.001492  \n",
       "7        0.024620        0.006335         0.001859  \n",
       "5        0.050215        0.003748         0.003694  \n",
       "2        0.060439        0.000331         0.000113  \n",
       "0        0.006754        0.000027         0.000014  \n",
       "1        0.031999        0.000027         0.000014  \n",
       "3        0.074574        0.000027         0.000014  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_clf.cv_results_ ).sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
